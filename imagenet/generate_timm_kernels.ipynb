{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦  loading timm/miniâ€‘imagenet â€¦\n",
      "âœ“ dataset ready â€” 8192 images\n",
      "\n",
      "ðŸš€  processing resnet18 â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d152d54f3bb409b805b610aa1e69b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                resnet18:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with looping\n",
      "features computed\n",
      "   â†³ saved  kernels_out_only_cnns/K_resnet18_8192.pt\n",
      "\n",
      "ðŸš€  processing resnet34 â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4538757a1b234faa83842973efceec4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                resnet34:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with looping\n",
      "features computed\n",
      "   â†³ saved  kernels_out_only_cnns/K_resnet34_8192.pt\n",
      "\n",
      "ðŸš€  processing resnet50 â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a8c0a7c7c845d88c1caa0069dc50c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                resnet50:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with looping\n",
      "features computed\n",
      "   â†³ saved  kernels_out_only_cnns/K_resnet50_8192.pt\n",
      "\n",
      "ðŸš€  processing resnet101 â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bae86171eb74ad8a9bcce69ead38efb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "               resnet101:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with looping\n",
      "features computed\n",
      "   â†³ saved  kernels_out_only_cnns/K_resnet101_8192.pt\n",
      "\n",
      "ðŸš€  processing resnet152 â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b8f389c96241c78c012aa23cacf8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "               resnet152:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with looping\n",
      "features computed\n",
      "   â†³ saved  kernels_out_only_cnns/K_resnet152_8192.pt\n",
      "\n",
      "ðŸš€  processing wide_resnet50_2 â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba511104b504d5b8e49cf7039915457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "         wide_resnet50_2:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with looping\n",
      "features computed\n",
      "   â†³ saved  kernels_out_only_cnns/K_wide_resnet50_2_8192.pt\n",
      "\n",
      "ðŸš€  processing wide_resnet101_2 â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21626755ca1d46d182d34d3af5163def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "        wide_resnet101_2:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with looping\n",
      "features computed\n",
      "   â†³ saved  kernels_out_only_cnns/K_wide_resnet101_2_8192.pt\n",
      "\n",
      "ðŸš€  processing resnext50_32x4d â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e9699e6b0746c2a0e13564a6f21991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "         resnext50_32x4d:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with looping\n",
      "features computed\n",
      "   â†³ saved  kernels_out_only_cnns/K_resnext50_32x4d_8192.pt\n",
      "\n",
      "ðŸš€  processing resnext101_32x8d â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d744242e85640ac96e357e2db001fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "        resnext101_32x8d:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with looping\n",
      "features computed\n",
      "   â†³ saved  kernels_out_only_cnns/K_resnext101_32x8d_8192.pt\n",
      "\n",
      "ðŸš€  processing densenet121 â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b61dd7b8c684be086ca2c9f94f11ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "             densenet121:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with looping\n",
      "features computed\n",
      "   â†³ saved  kernels_out_only_cnns/K_densenet121_8192.pt\n",
      "\n",
      "ðŸš€  processing densenet201 â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09390a9c62a943f3a82d715c50dcf234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "             densenet201:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with looping\n",
      "features computed\n",
      "   â†³ saved  kernels_out_only_cnns/K_densenet201_8192.pt\n",
      "\n",
      "ðŸš€  processing ese_vovnet39b â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6e1f613f72427cbb955be56a9f641a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "           ese_vovnet39b:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with looping\n",
      "features computed\n",
      "   â†³ saved  kernels_out_only_cnns/K_ese_vovnet39b_8192.pt\n",
      "\n",
      "ðŸš€  processing regnety_016 â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676e7f4ca6c54847a085efc9eefecf26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "             regnety_016:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with looping\n",
      "features computed\n",
      "   â†³ saved  kernels_out_only_cnns/K_regnety_016_8192.pt\n",
      "\n",
      "ðŸš€  processing regnety_032 â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e3869280f54673a709b54a41d5f3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "             regnety_032:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with looping\n",
      "features computed\n",
      "   â†³ saved  kernels_out_only_cnns/K_regnety_032_8192.pt\n",
      "\n",
      "âœ…  all kernels done.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "mini_imagenet_kernels_per_model.py\n",
    "----------------------------------\n",
    "â€¢ Uses the open timm/miniâ€‘imagenet dataset (50â€¯k images, 100 classes)\n",
    "â€¢ For each timm encoder in MODEL_NAMES:\n",
    "      â€“ extracts features on N_IMAGES random samples\n",
    "      â€“ builds its own cosineâ€‘similarity kernel  K = Z Záµ€\n",
    "      â€“ saves to  kernels_out/K_<model>.pt\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ userâ€‘tweakables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "N_IMAGES   = 8_192\n",
    "BATCH_SIZE = 1024\n",
    "NUM_WORKERS = 0\n",
    "DEVICE     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    # â”€â”€ Classic CNNs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    #\"resnet18\",\n",
    "    #\"resnet34\",\n",
    "    #\"resnet50\",\n",
    "    #\"resnet101\",\n",
    "    #\"resnet152\",\n",
    "    #\"wide_resnet50_2\",\n",
    "    #\"wide_resnet101_2\",\n",
    "    #\"resnext50_32x4d\",\n",
    "    #\"resnext101_32x8d\",\n",
    "    #\"densenet121\",\n",
    "    #\"densenet201\",\n",
    "    #\"ese_vovnet39b\",\n",
    "    #\"regnety_016\",\n",
    "    #\"regnety_032\",\n",
    "    # ConvNeXt family\n",
    "    #\"convnext_small\",\n",
    "    # EfficientNet & friends\n",
    "    #\"efficientnet_b0\",\n",
    "    # Mobile / lightweight\n",
    "    #\"mobilenetv3_large_100\",\n",
    "    #\"ghostnet_100\",\n",
    "    # NFâ€‘Nets (DeepMind)\n",
    "    #\"dm_nfnet_f0\",\n",
    "    # â”€â”€ Vision Transformers & hybrids â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # ViT\n",
    "    #\"vit_base_patch16_224\",\n",
    "    # DeiT\n",
    "    #\"deit_tiny_patch16_224\",\n",
    "    #\"deit_small_patch16_224\",\n",
    "    # BEiT\n",
    "    #\"beit_base_patch16_224\",\n",
    "    #\"beit_large_patch16_224\",\n",
    "    # Swin\n",
    "    #\"swin_tiny_patch4_window7_224\",\n",
    "    # PVTâ€‘v2\n",
    "    #\"pvt_v2_b2\",\n",
    "    # CSWin\n",
    "    #\"cswin_tiny_224\",\n",
    "    # CoAtNet\n",
    "    #\"coatnet_0\",\n",
    "    # Mixers / Convmixer\n",
    "    #\"mixer_b16_224\",\n",
    "    # GC ViT\n",
    "    #\"gcvit_base\",\n",
    "    # ConvNeXtâ€‘v2\n",
    "    #\"convnextv2_base\",\n",
    "    # CLIP ViT (image branch only)\n",
    "    #\"clip_vit_base_patch32\",\n",
    "]\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    # â”€â”€ Classic CNNs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    \"resnet18\",\n",
    "    \"resnet34\",\n",
    "    \"resnet50\",\n",
    "    \"resnet101\",\n",
    "    \"resnet152\",\n",
    "    \"wide_resnet50_2\",\n",
    "    \"wide_resnet101_2\",\n",
    "    \"resnext50_32x4d\",\n",
    "    \"resnext101_32x8d\",\n",
    "    \"densenet121\",\n",
    "    \"densenet201\",\n",
    "    \"ese_vovnet39b\",\n",
    "    \"regnety_016\",\n",
    "    \"regnety_032\"\n",
    "]\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ResNet family â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    \"resnet18\", \"resnet34\", \"resnet50\", \"resnet101\", \"resnet152\",\n",
    "    \"resnet26d\", \"resnet50d\", \"resnet50_gn\", \"resnet200d\",\n",
    "    \"wide_resnet50_2\", \"wide_resnet101_2\",\n",
    "    \"resnext50_32x4d\", \"resnext101_32x8d\", \"bat_resnext26ts\",\n",
    "    \"resnest50d\", \"resnest101e\", \"resnest200e\", \"resnest269e\",\n",
    "    \"seresnet50\", \"seresnet152\", \"seresnext50_32x4d\",\n",
    "    \"skresnet50\", \"skresnext50_32x4d\",\n",
    "]\n",
    "\n",
    "\n",
    "OUT_DIR = Path(\"kernels_out_only_cnns\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "\n",
    "# 1) Dataset -------------------------------------------------------------------\n",
    "print(\"ðŸ“¦  loading timm/miniâ€‘imagenet â€¦\")\n",
    "hf_ds = load_dataset(\"timm/mini-imagenet\", split=\"train\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img.convert(\"RGB\")),   # ensure 3â€‘ch\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class HFWrapper(Dataset):\n",
    "    def __init__(self, ds, tfm):\n",
    "        self.ds, self.tfm = ds, tfm\n",
    "    def __len__(self): return len(self.ds)\n",
    "    def __getitem__(self, i):\n",
    "        item = self.ds[int(i)]\n",
    "        return self.tfm(item[\"image\"]), item[\"label\"]\n",
    "\n",
    "# sample once, reuse for every model\n",
    "full_ds   = HFWrapper(hf_ds, transform)\n",
    "indices   = random.sample(range(len(full_ds)), N_IMAGES)\n",
    "subset_ds = Subset(full_ds, indices)\n",
    "loader    = DataLoader(subset_ds, batch_size=BATCH_SIZE,\n",
    "                       shuffle=False, num_workers=NUM_WORKERS,\n",
    "                       pin_memory=True)\n",
    "print(f\"âœ“ dataset ready â€” {len(subset_ds)} images\\n\")\n",
    "\n",
    "\n",
    "# 2) Feature â†’ kernel â†’ save  (one loop per model) -----------------------------\n",
    "\n",
    "@torch.no_grad()\n",
    "def features(model_name: str) -> torch.Tensor:\n",
    "    model = timm.create_model(model_name, pretrained=True,\n",
    "                              num_classes=0).to(DEVICE).eval()\n",
    "    vecs = []\n",
    "    for imgs, _ in tqdm(loader, desc=f\"{model_name:>24}\", leave=False):\n",
    "        # Process in smaller batches if needed\n",
    "        batch_output = model(imgs.to(DEVICE, non_blocking=True)).flatten(1)\n",
    "        # Convert to float32 for better memory efficiency\n",
    "        batch_output = batch_output.to(torch.float32)\n",
    "        vecs.append(batch_output)\n",
    "        # Explicitly free memory\n",
    "        torch.cuda.empty_cache()\n",
    "    print('done with looping')\n",
    "\n",
    "    return torch.cat(vecs)\n",
    "\n",
    "\n",
    "for m in MODEL_NAMES:\n",
    "    print(f\"ðŸš€  processing {m} â€¦\")\n",
    "    F_m = features(m)                            # (N, D_m)\n",
    "    print('features computed')\n",
    "    Z_m = F.normalize(F_m, p=2, dim=1)           # rowâ€‘norm\n",
    "    K_m = Z_m @ Z_m.T                            # (N, N)\n",
    "\n",
    "    torch.save(\n",
    "        {\"K\": K_m.cpu(),                         # kernel\n",
    "         \"Z\": F_m.cpu(),                         # normalised feats\n",
    "         \"dim\": F_m.shape[1],                    # feature length of this model\n",
    "         \"indices\": indices},\n",
    "        OUT_DIR / f\"K_{m}_{N_IMAGES}.pt\"\n",
    "    )\n",
    "    print(f\"   â†³ saved  {OUT_DIR / f'K_{m}_{N_IMAGES}.pt'}\\n\")\n",
    "\n",
    "    # Clean up memory before next model\n",
    "    del F_m, Z_m, K_m\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()  # Force garbage collection\n",
    "\n",
    "print(\"âœ…  all kernels done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
