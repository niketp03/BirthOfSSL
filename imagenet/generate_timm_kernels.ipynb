{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦  loading timm/miniâ€‘imagenet â€¦\n",
      "âœ“ dataset ready â€” 16384 images\n",
      "\n",
      "ðŸš€  processing resnet50 â€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31206ab6855640398914609169c8ad47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                resnet50:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "mini_imagenet_kernels_per_model.py\n",
    "----------------------------------\n",
    "â€¢ Uses the open timm/miniâ€‘imagenet dataset (50â€¯k images, 100 classes)\n",
    "â€¢ For each timm encoder in MODEL_NAMES:\n",
    "      â€“ extracts features on N_IMAGES random samples\n",
    "      â€“ builds its own cosineâ€‘similarity kernel  K = Z Záµ€\n",
    "      â€“ saves to  kernels_out/K_<model>.pt\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ userâ€‘tweakables â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "N_IMAGES   = 16_384\n",
    "BATCH_SIZE = 512  # Reduced batch size to lower memory footprint\n",
    "FEATURE_BATCH_SIZE = 2048  # Process kernel creation in chunks\n",
    "NUM_WORKERS = 1  # Reduced from 8 to lower memory pressure\n",
    "DEVICE     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    # CNNs\n",
    "    \"resnet50\", \"resnet152\",\n",
    "    \"convnext_base\",\n",
    "    \"efficientnet_b5\",\n",
    "    # ViT / MLPâ€‘Mixer style\n",
    "    \"vit_base_patch16_224\",\n",
    "    \"deit_base_patch16_224\",\n",
    "    \"swin_base_patch4_window7_224\"\n",
    "]\n",
    "\n",
    "OUT_DIR = Path(\"kernels_out_more_images\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "\n",
    "# 1) Dataset -------------------------------------------------------------------\n",
    "print(\"ðŸ“¦  loading timm/miniâ€‘imagenet â€¦\")\n",
    "hf_ds = load_dataset(\"timm/mini-imagenet\", split=\"train\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img.convert(\"RGB\")),   # ensure 3â€‘ch\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class HFWrapper(Dataset):\n",
    "    def __init__(self, ds, tfm):\n",
    "        self.ds, self.tfm = ds, tfm\n",
    "    def __len__(self): return len(self.ds)\n",
    "    def __getitem__(self, i):\n",
    "        item = self.ds[int(i)]\n",
    "        return self.tfm(item[\"image\"]), item[\"label\"]\n",
    "\n",
    "# sample once, reuse for every model\n",
    "full_ds   = HFWrapper(hf_ds, transform)\n",
    "indices   = random.sample(range(len(full_ds)), N_IMAGES)\n",
    "subset_ds = Subset(full_ds, indices)\n",
    "loader    = DataLoader(subset_ds, batch_size=BATCH_SIZE,\n",
    "                       shuffle=False, num_workers=NUM_WORKERS,\n",
    "                       pin_memory=True)\n",
    "print(f\"âœ“ dataset ready â€” {len(subset_ds)} images\\n\")\n",
    "\n",
    "\n",
    "# 2) Feature â†’ kernel â†’ save  (one loop per model) -----------------------------\n",
    "\n",
    "# 2) Feature â†’ kernel â†’ save  (one loop per model) -----------------------------\n",
    "@torch.no_grad()\n",
    "def features(model_name: str) -> torch.Tensor:\n",
    "    model = timm.create_model(model_name, pretrained=True,\n",
    "                              num_classes=0, global_pool=\"\").to(DEVICE).eval()\n",
    "    vecs = []\n",
    "    for imgs, _ in tqdm(loader, desc=f\"{model_name:>24}\", leave=False):\n",
    "        vecs.append(model(imgs.to(DEVICE, non_blocking=True)).flatten(1).cpu())\n",
    "    Z = torch.cat(vecs)                         # (N, D)\n",
    "    return F.normalize(Z, p=2, dim=1)           # row-normalize\n",
    "\n",
    "def compute_kernel_in_chunks(Z):\n",
    "    \"\"\"Compute kernel matrix in chunks to save memory\"\"\"\n",
    "    n = Z.shape[0]\n",
    "    K = torch.zeros((n, n), dtype=Z.dtype)\n",
    "    \n",
    "    for i in tqdm(range(0, n, FEATURE_BATCH_SIZE), desc=\"Computing kernel chunks\"):\n",
    "        end_idx = min(i + FEATURE_BATCH_SIZE, n)\n",
    "        # Compute one chunk of rows at a time\n",
    "        K[i:end_idx] = Z[i:end_idx] @ Z.T\n",
    "        # Explicitly delete intermediate tensors\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    \n",
    "    return K\n",
    "\n",
    "for m in MODEL_NAMES:\n",
    "    print(f\"ðŸš€  processing {m} â€¦\")\n",
    "    \n",
    "    # Process and immediately normalize features\n",
    "    Z_m = features(m)                            # (N, D_m), already normalized\n",
    "    print(f\"   â†³ features extracted, shape: {Z_m.shape}\")\n",
    "    \n",
    "    # Compute kernel matrix in chunks\n",
    "    K_m = compute_kernel_in_chunks(Z_m)\n",
    "    print(f\"   â†³ kernel computed, shape: {K_m.shape}\")\n",
    "    \n",
    "    # Save immediately to free memory\n",
    "    torch.save(\n",
    "        {\"K\": K_m.cpu(),                         # kernel\n",
    "         \"Z\": Z_m.cpu(),                         # normalised feats\n",
    "         \"dim\": Z_m.shape[1],                    # feature length of this model\n",
    "         \"indices\": indices},\n",
    "        OUT_DIR / f\"K_{m}_{N_IMAGES}.pt\"\n",
    "    )\n",
    "    print(f\"   â†³ saved  {OUT_DIR / f'K_{m}_{N_IMAGES}.pt'}\")\n",
    "    \n",
    "    # Explicitly free memory\n",
    "    del Z_m, K_m\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    print()\n",
    "\n",
    "print(\"âœ…  all kernels done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
