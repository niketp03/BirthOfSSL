{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading ResNet models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from ResNet models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74bc47f9ad4c490c88f06ca4e6c27bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68596c9c8c8e49d69e83ab9b57a7587e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b956aed8dd634e349cdb48cae15b9874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating kernel matrices...\n",
      "Sampling with temperature T=0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723edf596195489185f51fc4fc93c516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sampling traces with T=0.1:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 139\u001b[0m\n\u001b[1;32m    137\u001b[0m T \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m  \u001b[38;5;66;03m# Temperature parameter\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampling with temperature T=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 139\u001b[0m traces_resnet18 \u001b[38;5;241m=\u001b[39m sample_tr_kg(kernel_resnet18, M, T\u001b[38;5;241m=\u001b[39mT, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[1;32m    140\u001b[0m traces_resnet50 \u001b[38;5;241m=\u001b[39m sample_tr_kg(kernel_resnet50, M, T\u001b[38;5;241m=\u001b[39mT, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[1;32m    141\u001b[0m traces_resnet152 \u001b[38;5;241m=\u001b[39m sample_tr_kg(kernel_resnet152, M, T\u001b[38;5;241m=\u001b[39mT, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 95\u001b[0m, in \u001b[0;36msample_tr_kg\u001b[0;34m(K, M, T, num_samples)\u001b[0m\n\u001b[1;32m     91\u001b[0m edge_probs \u001b[38;5;241m=\u001b[39m scipy\u001b[38;5;241m.\u001b[39mspecial\u001b[38;5;241m.\u001b[39mexpit(M \u001b[38;5;241m/\u001b[39m T)  \u001b[38;5;66;03m# sigmoid function\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m trange(num_samples, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampling traces with T=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# Create random adjacency matrix G where each edge is Bernoulli with p = sigmoid(M_ij / T)\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     G \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mbinomial(\u001b[38;5;241m1\u001b[39m, edge_probs)\n\u001b[1;32m     96\u001b[0m     np\u001b[38;5;241m.\u001b[39mfill_diagonal(G, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# No self-loops\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# Compute Tr(KG)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms, models\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "import tarfile\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import scipy.special\n",
    "\n",
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(160),\n",
    "    transforms.CenterCrop(160),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Paths for the Imagenette dataset\n",
    "imagenette_root = \"./data/imagenette2-160\"\n",
    "train_dir = os.path.join(imagenette_root, \"train\")\n",
    "val_dir = os.path.join(imagenette_root, \"val\")\n",
    "\n",
    "# download & extract if not already present\n",
    "if not os.path.isdir(imagenette_root):\n",
    "    os.makedirs(os.path.dirname(imagenette_root), exist_ok=True)\n",
    "    url = \"https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-160.tgz\"\n",
    "    archive_path = os.path.join(os.path.dirname(imagenette_root), \"imagenette2-160.tgz\")\n",
    "    if not os.path.exists(archive_path):\n",
    "        print(\"Downloading Imagenette dataset...\")\n",
    "        import urllib.request\n",
    "        urllib.request.urlretrieve(url, archive_path)\n",
    "    print(\"Extracting Imagenette dataset...\")\n",
    "    with tarfile.open(archive_path, \"r:gz\") as tar:\n",
    "        tar.extractall(path=os.path.dirname(imagenette_root))\n",
    "    print(\"Done.\")\n",
    "\n",
    "# Load the test dataset\n",
    "test_dataset = ImageFolder(val_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Function to center the kernel matrix\n",
    "def centre_kernel(K):\n",
    "    n = K.shape[0]\n",
    "    unit = np.ones([n, n]) / n\n",
    "    return K - unit.dot(K) - K.dot(unit) + unit.dot(K).dot(unit)\n",
    "\n",
    "# Function to extract features from a model\n",
    "def extract_features(model, dataloader, device):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, _ in tqdm(dataloader, desc=\"Extracting features\"):\n",
    "            images = torch.nn.functional.interpolate(\n",
    "                images, size=(224,224), mode='bilinear', align_corners=False\n",
    "            ).to(device)\n",
    "            # Forward pass through the model\n",
    "            feat = model(images)\n",
    "            features.append(feat.cpu())\n",
    "    \n",
    "    return torch.cat(features)\n",
    "\n",
    "# Function to create a normalized kernel matrix from features\n",
    "def create_kernel_matrix(features):\n",
    "    # Convert to numpy for easier manipulation\n",
    "    features_np = features.numpy()\n",
    "    \n",
    "    # Normalize features\n",
    "    norms = np.sqrt(np.sum(features_np**2, axis=1, keepdims=True))\n",
    "    normed_features = features_np / norms\n",
    "    \n",
    "    # Create kernel matrix (dot product of normalized features)\n",
    "    kernel_matrix = normed_features @ normed_features.T\n",
    "    \n",
    "    # Center the kernel\n",
    "    centered_kernel = centre_kernel(kernel_matrix)\n",
    "    \n",
    "    return centered_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading ResNet models...\n",
      "Extracting features from ResNet models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d6bee0159542db9669176759d356b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a852e1ce74422e8abcd3ce0d7d00a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting features from ResNet models...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m features_resnet18 \u001b[38;5;241m=\u001b[39m extract_features(resnet18, test_loader, device)\n\u001b[0;32m---> 59\u001b[0m features_resnet50 \u001b[38;5;241m=\u001b[39m extract_features(resnet50, test_loader, device)\n\u001b[1;32m     60\u001b[0m features_resnet152 \u001b[38;5;241m=\u001b[39m extract_features(resnet152, test_loader, device)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Create kernel matrices\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 59\u001b[0m, in \u001b[0;36mextract_features\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, _ \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting features\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 59\u001b[0m         images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39minterpolate(\n\u001b[1;32m     60\u001b[0m             images, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m,\u001b[38;5;241m224\u001b[39m), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     61\u001b[0m         )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;66;03m# Forward pass through the model\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         feat \u001b[38;5;241m=\u001b[39m model(images)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/functional.py:4580\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   4571\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mare_deterministic_algorithms_enabled() \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m   4572\u001b[0m             \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mis_cuda \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mis_xpu\n\u001b[1;32m   4573\u001b[0m         ):\n\u001b[1;32m   4574\u001b[0m             \u001b[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put\u001b[39;00m\n\u001b[1;32m   4575\u001b[0m             \u001b[38;5;66;03m# importlib is required because the import cannot be top level\u001b[39;00m\n\u001b[1;32m   4576\u001b[0m             \u001b[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001b[39;00m\n\u001b[1;32m   4577\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\n\u001b[1;32m   4578\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch._decomp.decompositions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4579\u001b[0m             )\u001b[38;5;241m.\u001b[39m_upsample_linear_vec(\u001b[38;5;28minput\u001b[39m, output_size, align_corners, scale_factors)\n\u001b[0;32m-> 4580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mupsample_bilinear2d(\n\u001b[1;32m   4581\u001b[0m         \u001b[38;5;28minput\u001b[39m, output_size, align_corners, scale_factors\n\u001b[1;32m   4582\u001b[0m     )\n\u001b[1;32m   4583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   4584\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m align_corners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the three ResNet models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"Loading ResNet models...\")\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "resnet18.fc = torch.nn.Identity()  # Remove classification layer\n",
    "resnet18 = resnet18.to(device)\n",
    "\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet50.fc = torch.nn.Identity()  # Remove classification layer\n",
    "resnet50 = resnet50.to(device)\n",
    "\n",
    "resnet152 = models.resnet152(pretrained=True)\n",
    "resnet152.fc = torch.nn.Identity()  # Remove classification layer\n",
    "resnet152 = resnet152.to(device)\n",
    "\n",
    "# Extract features for each model\n",
    "print(\"Extracting features from ResNet models...\")\n",
    "features_resnet18 = extract_features(resnet18, test_loader, device)\n",
    "features_resnet50 = extract_features(resnet50, test_loader, device)\n",
    "features_resnet152 = extract_features(resnet152, test_loader, device)\n",
    "\n",
    "# Create kernel matrices\n",
    "print(\"Creating kernel matrices...\")\n",
    "kernel_resnet18 = create_kernel_matrix(features_resnet18)\n",
    "kernel_resnet50 = create_kernel_matrix(features_resnet50)\n",
    "kernel_resnet152 = create_kernel_matrix(features_resnet152)\n",
    "\n",
    "# Use ResNet50's kernel as the base for the graph sampling (M)\n",
    "M = kernel_resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling with temperature T=0.1\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 29.4 GiB for an array with shape (256, 3925, 3925) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m T \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m  \u001b[38;5;66;03m# Temperature parameter\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampling with temperature T=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m traces_resnet18 \u001b[38;5;241m=\u001b[39m sample_tr_kg(kernel_resnet18, M, T\u001b[38;5;241m=\u001b[39mT, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m     44\u001b[0m traces_resnet50 \u001b[38;5;241m=\u001b[39m sample_tr_kg(kernel_resnet50, M, T\u001b[38;5;241m=\u001b[39mT, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m     45\u001b[0m traces_resnet152 \u001b[38;5;241m=\u001b[39m sample_tr_kg(kernel_resnet152, M, T\u001b[38;5;241m=\u001b[39mT, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m, in \u001b[0;36msample_tr_kg\u001b[0;34m(K, M, T, num_samples)\u001b[0m\n\u001b[1;32m     12\u001b[0m K_weighted \u001b[38;5;241m=\u001b[39m K \u001b[38;5;241m*\u001b[39m edge_probs\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Use vectorized operations for sampling\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Generate all random samples at once\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m random_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandom((num_samples, n, n))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Create a progress bar\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trange(num_samples, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampling traces with T=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Preallocate array for traces\u001b[39;00m\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:446\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.random\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:437\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.random_sample\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_common.pyx:307\u001b[0m, in \u001b[0;36mnumpy.random._common.double_fill\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 29.4 GiB for an array with shape (256, 3925, 3925) and data type float64"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to sample Tr(KG) where G is sampled using sigmoid(M/T)\n",
    "def sample_tr_kg(K, M, T=1.0, num_samples=1000):\n",
    "    n = K.shape[0]\n",
    "    \n",
    "    # Compute edge probabilities using sigmoid(M_ij / T)\n",
    "    edge_probs = scipy.special.expit(M / T)  # sigmoid function\n",
    "    \n",
    "    # Set diagonal to 0 probability (no self-loops)\n",
    "    np.fill_diagonal(edge_probs, 0)\n",
    "    \n",
    "    # Pre-compute K * edge_probs for weighted sampling\n",
    "    K_weighted = K * edge_probs\n",
    "    \n",
    "    # Use vectorized operations for sampling\n",
    "    # Generate all random samples at once\n",
    "    random_values = np.random.random((num_samples, n, n))\n",
    "    \n",
    "    # Create a progress bar\n",
    "    with trange(num_samples, desc=f\"Sampling traces with T={T}\") as pbar:\n",
    "        # Preallocate array for traces\n",
    "        traces = np.zeros(num_samples)\n",
    "        \n",
    "        # Process in batches to avoid memory issues\n",
    "        batch_size = 50\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            end_idx = min(i + batch_size, num_samples)\n",
    "            batch_count = end_idx - i\n",
    "            \n",
    "            # Generate batch of adjacency matrices\n",
    "            G_batch = (random_values[i:end_idx] < edge_probs).astype(np.float32)\n",
    "            \n",
    "            # Compute traces for the batch\n",
    "            traces[i:end_idx] = np.sum(K * G_batch, axis=(1, 2))\n",
    "            \n",
    "            pbar.update(batch_count)\n",
    "    \n",
    "    return traces\n",
    "\n",
    "\n",
    "# Sample Tr(KG) for each kernel with fixed temperature\n",
    "T = 0.1  # Temperature parameter\n",
    "print(f\"Sampling with temperature T={T}\")\n",
    "traces_resnet18 = sample_tr_kg(kernel_resnet18, M, T=T, num_samples=256)\n",
    "traces_resnet50 = sample_tr_kg(kernel_resnet50, M, T=T, num_samples=256)\n",
    "traces_resnet152 = sample_tr_kg(kernel_resnet152, M, T=T, num_samples=256)\n",
    "\n",
    "# Create KDE plots\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.kdeplot(traces_resnet18, label=\"ResNet-18\", fill=True, alpha=0.3)\n",
    "sns.kdeplot(traces_resnet50, label=\"ResNet-50\", fill=True, alpha=0.3)\n",
    "sns.kdeplot(traces_resnet152, label=\"ResNet-152\", fill=True, alpha=0.3)\n",
    "\n",
    "plt.title(f\"Distribution of Tr(KG) for Different ResNet Models (T={T})\", fontsize=16)\n",
    "plt.xlabel(\"Tr(KG)\", fontsize=14)\n",
    "plt.ylabel(\"Density\", fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add statistics to the plot\n",
    "stats_text = []\n",
    "for name, traces in [(\"ResNet-18\", traces_resnet18), \n",
    "                     (\"ResNet-50\", traces_resnet50), \n",
    "                     (\"ResNet-152\", traces_resnet152)]:\n",
    "    mean = np.mean(traces)\n",
    "    std = np.std(traces)\n",
    "    stats_text.append(f\"{name}: Mean = {mean:.2f}, Std = {std:.2f}\")\n",
    "\n",
    "plt.figtext(0.5, 0.01, \"\\n\".join(stats_text), ha=\"center\", fontsize=12, \n",
    "            bbox={\"facecolor\":\"white\", \"alpha\":0.8, \"pad\":5})\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.95])\n",
    "plt.savefig(f\"resnet_trace_distributions_T{T}.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Create a DataFrame for easier analysis\n",
    "trace_df = pd.DataFrame({\n",
    "    'ResNet-18': traces_resnet18,\n",
    "    'ResNet-50': traces_resnet50,\n",
    "    'ResNet-152': traces_resnet152\n",
    "})\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(trace_df.describe())\n",
    "\n",
    "# Save the raw data\n",
    "np.savez(f\"resnet_trace_data_T{T}.npz\", \n",
    "         resnet18=traces_resnet18, \n",
    "         resnet50=traces_resnet50, \n",
    "         resnet152=traces_resnet152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
